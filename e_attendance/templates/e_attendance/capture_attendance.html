{% extends "e_attendance/layout.html" %}

{% load user_group_tag %}

{% block title %}
Capture {{ attendance_type|title }} Attendance
{% endblock %}

{% load static %}

{% block body %}
<div id="attendance-type" class="d-none">{{ attendance_type}}</div>
<div id="event-id" class="d-none">{{ event.id }}</div>

{% if attendance_type == "event" %}
<h2 class="text-center">Capture {{ attendance_type|title }} ({{ event.name|title }}) Attendance</h2>
{% else %}
<h2 class="text-center">Capture {{ attendance_type|title }} Attendance</h2>
{% endif %}

<!-- you have successfuly time in or time out -->
<div id="alert" class="alert alert-dismissible fade show" role="alert">
    <div id="alert-message" class="text-center"></div>
    <button type="button" class="btn-close" aria-label="Close"></button>
</div>

<!-- loading circle -->
<div id="spinner" style="
        height: 80vh; 
        display: none; 
        flex-direction: column; 
        align-items: center; 
        justify-content: center;">
    <div class="spinner-border" style="width: 4rem; height: 4rem;" role="status"></div>
    <div class="fw-bold">Processing...</div>
</div>

<div id="video-container" style="
    position: relative;
    width: 90%; 
    max-width: 576px;
    margin-inline: auto;
    display: flex;
    flex-direction: column;
    align-items: center;">
    <video style="width: 100%; height: auto;"></video>
    <canvas style="
        position: absolute; 
        top: 0; 
        left: 0;">
    </canvas>
    <button id="video-btn" class="btn btn-primary mt-3">Pause</button>
</div>

<!-- button for opening the modal -->
<button id="open-confirm-recognition-modal-btn" type="button" class="btn btn-primary" data-bs-toggle="modal"
    data-bs-target="#confirm-recognition-modal" style="visibility: hidden;">
</button>

<!-- Modal -->
<div class="modal fade" id="confirm-recognition-modal" tabindex="-1">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h1 class="modal-title fs-5">Confirm recognition</h1>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <div id="result" class="d-flex flex-column align-items-center">
                    <p id="result-text" class="text-center"></p>
                    <p>Is this correct?</p>
                    <div>
                        <button class="btn btn-success" id="confirm-recognition-btn">Yes</button>
                        <button class="btn btn-danger" data-bs-dismiss="modal">No</button>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>


<script src="{% static 'e_attendance/js/face-api.js' %}"></script>
<script src="{% static 'e_attendance/js/getCookie.js' %}" type="text/javascript"></script>
<script>
    // Path to the face recognition models.
    // const MODEL_URL = "../../../static/e_attendance/face_recognition_models"
    const MODEL_URL = "/static/e_attendance/face_recognition_models"


    // Load all face recognition models.
    Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        // faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
        faceapi.nets.faceLandmark68TinyNet.loadFromUri(MODEL_URL),
        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
        // faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)
    ]).then(start)

    const alert = document.querySelector("#alert")
    alert.style.display = "none"
    const alertCloseBtn = alert.querySelector(".btn-close")
    alertCloseBtn.onclick = () => alert.style.display = "none"
    
    const spinner = document.querySelector("#spinner")
    const videoContainer = document.querySelector("#video-container")
    const videoElement = document.querySelector("video")
    const canvasElement = document.querySelector("canvas")
    const videoBtn = document.querySelector("#video-btn")
    const confirmRecognitionBtn = document.querySelector("#confirm-recognition-btn")


    let labeledFaceDescriptors
    let faceMatcher

    async function start() {
        // Hide the video when loading the images.
        spinner.style.display = "flex"
        videoContainer.style.display = "none"
        // Load and process the sample images for face recognition.
        labeledFaceDescriptors = await loadImages()
        if (labeledFaceDescriptors.length) {
            faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, 0.4)
        }
        spinner.style.display = "none"
        videoContainer.style.display = "flex"
        // Start the device's camera then play the video on the page.
        navigator.mediaDevices.getUserMedia({ video: true, audio: false })
            .then((stream) => {
                videoElement.srcObject = stream,
                    videoElement.play()
            })
            .catch((err) => {
                console.error(`An error occurred: ${err}`);
            });
    }


    ///////////////////////////////// HELPER FUNCTIONS /////////////////////////////////////////////

    // To load and process the sample images used for face recognition.
    async function loadImages() {
        let users = [
            { name: "Noel Laurence L. Delos Reyes", id: 2, groups: ["students"] },
            { name: "Aljon A. Dalaten", id: 11, groups: ["students"] },
            { name: "Jenelyn C. Hasad", id: 8, groups: ["students"] },
            { name: "Justin S. Ejanda", id: 12, groups: ["students"] },
            { name: "Rea M. Garcia", id: 4, groups: ["students"] },
            { name:"Ricky A. Quindara", id:26, groups: ["students"] },
            { name: "migel", id: 45, groups: ["faculty"]},
            { name: "Richard M. Aquino", id: 46, groups: ["students"] }
        ]

        let attendanceType = document.querySelector("#attendance-type").innerHTML
        if (attendanceType === "faculty") {
            users = users.filter(user => user.groups.includes(attendanceType))
        }
        else if (attendanceType === "event") {
            users = users.filter(user => user.groups.includes("students"))
        }
        
        let labeledFaceDescriptors = JSON.parse(localStorage.getItem("labeledFaceDescriptors"))
        if (labeledFaceDescriptors === null) {
            localStorage.setItem("labeledFaceDescriptors", JSON.stringify([]))
            labeledFaceDescriptors = []
        }
        let promises = Promise.all(
            users.map(async user => {
                let labeledFaceDescriptor = labeledFaceDescriptors.find(item => item.label === user.name + "," + user.id)
                if (labeledFaceDescriptor) {
                    console.log("found")
                    return new faceapi.LabeledFaceDescriptors(labeledFaceDescriptor.label, [new Float32Array(labeledFaceDescriptor.descriptors[0])])
                }
                else {
                    try {
                        console.log(`start ${user.name} fetchImage`)
                        const img = await faceapi.fetchImage(`../../../static/e_attendance/images/faces/${user.name}.jpg`)
                        console.log(`end ${user.name} fetchImage`)
                        console.log(`start ${user.name} detection`)
                        const detection = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions({ inputSize: 160 })).withFaceLandmarks(true).withFaceDescriptor()
                        console.log(`end ${user.name} detection`)
                        let labeledFaceDescriptor = new faceapi.LabeledFaceDescriptors(user.name + "," + user.id, [detection.descriptor])
                        labeledFaceDescriptors.push(labeledFaceDescriptor)
                        return labeledFaceDescriptor
                    }
                    catch (err) {
                        console.log(err)
                    }
                }
            })
        )

        localStorage.setItem("labeledFaceDescriptors", JSON.stringify(labeledFaceDescriptors))
        return promises
    }

    let displaySize

    function resizeCanvas() {
        // Get the dimensions of the video element.
        displaySize = { width: videoElement.clientWidth, height: videoElement.clientHeight }
        // Resize the canvas to the video's dimensions.
        faceapi.matchDimensions(canvasElement, displaySize)
    }
    ///////////////////////////////////// EVENT LISTENERS ///////////////////////////////////////////////

    let interval
    // This function will run when the video from camera starts showing up.
    // Or the "Play video" button is pressed.
    videoElement.addEventListener("play", async () => {
        videoBtn.innerHTML = "Pause"

        // This function will run every 0.25 secs.
        interval = setInterval(async () => {

            // Detect face in the video.
            const detections = await faceapi.detectSingleFace(videoElement, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks(true).withFaceDescriptor()

            // Resize the detection box in case the displayed video has a different size than the original.
            const resizedDetections = faceapi.resizeResults(detections, displaySize)

            // To match the detected face against the sample images.   to compare and match faces
            const result = faceMatcher.findBestMatch(resizedDetections.descriptor)
            let userFullName = result._label.split(",")[0]
            let userId = result._label.split(",")[1]
            const box = resizedDetections.detection.box
            const drawBox = new faceapi.draw.DrawBox(box, {
                label: `${userFullName} (${result._distance.toFixed(2)})`
            })
            // Clear the canvas before drawing.
            canvasElement.getContext("2d").clearRect(0, 0, canvasElement.width, canvasElement.height)
            // Draw the box around the face.
            drawBox.draw(canvasElement)

            // If a face is recognized, ask the user if the recognition is correct.
            if (result._label != "unknown") {
                videoElement.pause()
                document.querySelector("#open-confirm-recognition-modal-btn").click()
                document.querySelector("#result-text").innerHTML = `Recognized as <b>${userFullName}</b>`
                confirmRecognitionBtn.dataset.userId = userId
            }
        }, 250)
    })


    // This function will run if the video is paused.
    videoElement.addEventListener("pause", () => {
        clearInterval(interval)
        videoBtn.innerHTML = "Play"
    })


    videoElement.addEventListener("canplay", resizeCanvas)


    window.addEventListener("resize", resizeCanvas)


    videoBtn.addEventListener("click", () => {
        if (videoElement.paused) {
            videoElement.play()
        }
        else {
            videoElement.pause()
        }
    })


    const successMessageContainer = document.querySelector("#success-message-container")

    // This function will run if the user confirmed that the recognition is correct.
    // It will send a request to the server to add a database record of the employee's attendance.
    confirmRecognitionBtn.addEventListener("click", async (e) => {
        let response = await fetch("/capture_attendance", {
            method: "POST",
            mode: "same-origin",
            headers: { "X-CSRFToken": getCookie('csrftoken') },
            body: JSON.stringify({
                user_id: e.target.dataset.userId,
                attendance_type: document.querySelector("#attendance-type").innerHTML,
                event_id: document.querySelector("#event-id").innerHTML
            })
        })
        let text = await response.text()

        document.querySelector("#confirm-recognition-modal").querySelector(".btn-close").click()
        alert.style.display = "block"
        alert.querySelector("#alert-message").innerHTML = text
        if (response.ok) {
            alert.classList.add("alert-success")
        }
        else {
            alert.classList.add("alert-danger")
        }
    })
</script>
{% endblock %}